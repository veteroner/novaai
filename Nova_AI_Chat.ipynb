{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ğŸš€ Nova AI Chat - Google Colab\n",
        "\n",
        "Teknova'nÄ±n Nova AI'sÄ±nÄ± Google Colab'da Ã¼cretsiz GPU ile Ã§alÄ±ÅŸtÄ±rÄ±n!\n",
        "\n",
        "ğŸ“‹ AdÄ±mlar:\n",
        "1. GPU'yu etkinleÅŸtirin (Runtime > Change runtime type > GPU)  \n",
        "2. TÃ¼m hÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n\n",
        "3. Son hÃ¼credeki baÄŸlantÄ±yÄ± aÃ§Ä±p Nova AI ile sohbet edin!\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸš€ Nova AI Chat - Google Colab BaÅŸlÄ±yor!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“¦ Gerekli paketleri yÃ¼kle\n",
        "print(\"ğŸš€ Paketler yÃ¼kleniyor...\")\n",
        "!pip install -q transformers accelerate bitsandbytes gradio torch\n",
        "print(\"âœ… Paketler yÃ¼klendi!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“š KÃ¼tÃ¼phaneleri iÃ§e aktar\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(f\"ğŸ”¥ GPU kullanÄ±labilir: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ“± GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ Nova AI modelini yÃ¼kle\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "print(\"ğŸš€ Nova AI modeli yÃ¼kleniyor... (2-3 dakika sÃ¼rebilir)\")\n",
        "print(\"ğŸ’¡ Teknova tarafÄ±ndan optimize edilmiÅŸ\")\n",
        "\n",
        "# Tokenizer yÃ¼kle\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(\"âœ… Nova AI Tokenizer yÃ¼klendi\")\n",
        "\n",
        "# Model yÃ¼kle - 8-bit quantization ile hafÄ±za tasarrufu\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    load_in_8bit=True\n",
        ")\n",
        "\n",
        "print(\"ğŸ‰ Nova AI hazÄ±r! ArtÄ±k sohbet edebilirsiniz.\")\n",
        "print(\"ğŸš€ Teknova ile gÃ¼Ã§lendirilmiÅŸtir\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ’¬ Nova AI Chat fonksiyonu\n",
        "def chat_response(message, history):\n",
        "    \"\"\"Nova AI ile sohbet et\"\"\"\n",
        "    if not message.strip():\n",
        "        return \"â“ LÃ¼tfen Nova AI'ya bir mesaj yazÄ±n.\"\n",
        "    \n",
        "    try:\n",
        "        # Sohbet geÃ§miÅŸini formatla\n",
        "        conversation = \"\"\n",
        "        for user_msg, bot_msg in history:\n",
        "            conversation += f\"[INST] {user_msg} [/INST] {bot_msg} \"\n",
        "        \n",
        "        # Yeni mesajÄ± ekle\n",
        "        conversation += f\"[INST] {message} [/INST]\"\n",
        "        \n",
        "        # Tokenize et\n",
        "        inputs = tokenizer(\n",
        "            conversation, \n",
        "            return_tensors=\"pt\", \n",
        "            truncation=True, \n",
        "            max_length=2048\n",
        "        ).to(model.device)\n",
        "        \n",
        "        # YanÄ±t Ã¼ret\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=512,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "        \n",
        "        # YanÄ±tÄ± decode et\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        \n",
        "        # Sadece yeni Ã¼retilen kÄ±smÄ± al\n",
        "        new_response = response[len(conversation):].strip()\n",
        "        \n",
        "        return new_response\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"âŒ Hata: {str(e)}\"\n",
        "\n",
        "print(\"âœ… Nova AI Chat fonksiyonu hazÄ±r!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¨ Nova AI Gradio arayÃ¼zÃ¼ oluÅŸtur\n",
        "with gr.Blocks(\n",
        "    theme=gr.themes.Soft(),\n",
        "    title=\"Nova AI Chat - Teknova\"\n",
        ") as demo:\n",
        "    \n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; padding: 20px; background: linear-gradient(135deg, #ff6b6b 0%, #4ecdc4 100%); color: white; border-radius: 10px; margin-bottom: 20px;\">\n",
        "        <h1>ğŸš€ Nova AI Chat</h1>\n",
        "        <p>Google Colab'da Ã§alÄ±ÅŸan <strong>Teknova</strong> AI asistanÄ±nÄ±z</p>\n",
        "        <small>âš¡ GPU hÄ±zlandÄ±rmalÄ± â€¢ ğŸ§  GeliÅŸmiÅŸ AI â€¢ ğŸš€ Teknova</small>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "    \n",
        "    chatbot = gr.Chatbot(\n",
        "        height=400,\n",
        "        show_label=False,\n",
        "        show_share_button=True,\n",
        "        show_copy_button=True\n",
        "    )\n",
        "    \n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(\n",
        "            placeholder=\"Nova AI'ya mesajÄ±nÄ±zÄ± yazÄ±n... (TÃ¼rkÃ§e sorular sorabilirsiniz)\",\n",
        "            show_label=False,\n",
        "            scale=4\n",
        "        )\n",
        "        submit = gr.Button(\"ğŸš€ GÃ¶nder\", scale=1, variant=\"primary\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        clear = gr.Button(\"ğŸ—‘ï¸ Temizle\", scale=1)\n",
        "        \n",
        "    gr.HTML(\"\"\"\n",
        "    <div style=\"text-align: center; padding: 15px; background: #f0f0f0; border-radius: 8px; margin-top: 10px;\">\n",
        "        <h3>ğŸ’¡ Nova AI'ya sorabilecekleriniz:</h3>\n",
        "        <p>â€¢ \"Python'da liste comprehension nasÄ±l kullanÄ±lÄ±r?\"</p>\n",
        "        <p>â€¢ \"TÃ¼rkiye'nin baÅŸkenti neresidir?\"</p>\n",
        "        <p>â€¢ \"Bana bir hikaye anlat\"</p>\n",
        "        <p>â€¢ \"Yapay zeka nedir?\"</p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "    \n",
        "    # Event handlers\n",
        "    def user_message(message, history):\n",
        "        return \"\", history + [[message, None]]\n",
        "    \n",
        "    def bot_message(history):\n",
        "        user_message = history[-1][0]\n",
        "        bot_response = chat_response(user_message, history[:-1])\n",
        "        history[-1][1] = bot_response\n",
        "        return history\n",
        "    \n",
        "    msg.submit(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot_message, chatbot, chatbot\n",
        "    )\n",
        "    submit.click(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot_message, chatbot, chatbot\n",
        "    )\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "print(\"ğŸ¨ Nova AI arayÃ¼zÃ¼ hazÄ±r!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ Nova AI UygulamasÄ±nÄ± baÅŸlat\n",
        "print(\"ğŸŒŸ Nova AI Chat uygulamasÄ± baÅŸlatÄ±lÄ±yor...\")\n",
        "print(\"ğŸ“± AÅŸaÄŸÄ±daki baÄŸlantÄ±yÄ± aÃ§Ä±p sohbet etmeye baÅŸlayÄ±n!\")\n",
        "\n",
        "demo.launch(\n",
        "    share=True,  # Herkesle paylaÅŸÄ±labilir link\n",
        "    debug=True,\n",
        "    show_error=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ğŸ‰ Tebrikler!\n",
        "\n",
        "Nova AI Chat artÄ±k Ã§alÄ±ÅŸÄ±yor! \n",
        "\n",
        "ğŸ“‹ KullanÄ±m Ä°puÃ§larÄ±:\n",
        "- ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e sorular sorun\n",
        "- ğŸ’¬ Uzun sohbetler yapabilirsiniz  \n",
        "- ğŸ”„ \"Temizle\" ile geÃ§miÅŸi silin\n",
        "- âš¡ GPU sayesinde hÄ±zlÄ± yanÄ±tlar\n",
        "- ğŸš€ Nova AI teknolojisini deneyimleyin\n",
        "\n",
        "ğŸ”— PaylaÅŸÄ±m:\n",
        "- YukarÄ±daki public link'i paylaÅŸabilirsiniz\n",
        "- Link 72 saat aktif kalÄ±r\n",
        "- Colab kapatÄ±lÄ±rsa link devre dÄ±ÅŸÄ± kalÄ±r\n",
        "\n",
        "ğŸŒŸ Nova AI Ã–zellikleri:\n",
        "- Teknova kalitesi garantisi\n",
        "- GeliÅŸmiÅŸ AI teknolojisi\n",
        "- HÄ±zlÄ± ve gÃ¼venilir yanÄ±tlar\n",
        "\n",
        "ğŸš€ Teknova Nova AI ile gÃ¼Ã§lendirilmiÅŸtir\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ“˜ Nova AI Chat kullanÄ±m rehberi yukarÄ±da!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
