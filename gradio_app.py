import gradio as gr
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import os

# Nova AI Model bilgileri - Teknova'nÄ±n Ã¶zgÃ¼n modeli
MODEL_NAME = "./nova-ai-model"  # Kendi Nova AI modelinizin yolu
MODEL_PATH = "/content/nova-ai-model"  # Colab iÃ§in path

# ArtÄ±k token gerekmiyor - kendi modeliniz
print("ğŸš€ Teknova Nova AI - Ã–zgÃ¼n model yÃ¼kleniyor...")
print("ğŸ’¡ Hugging Face token gerektirmez - tamamen Ã¶zgÃ¼n!")

# Global deÄŸiÅŸkenler
model = None
tokenizer = None

def load_model():
    """Teknova Nova AI modelini yÃ¼kle - Ã–zgÃ¼n model"""
    global model, tokenizer
    
    print("ğŸš€ Teknova Nova AI modeli yÃ¼kleniyor...")
    print("ğŸŒŸ Bu tamamen Ã¶zgÃ¼n bir Teknova Nova AI modelidir!")
    
    # Colab iÃ§in model path kontrolÃ¼
    model_path = MODEL_PATH if os.path.exists(MODEL_PATH) else MODEL_NAME
    
    try:
        # Nova AI Tokenizer yÃ¼kle
        tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        
        # Nova AI Model yÃ¼kle - Teknova optimizasyonu
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            device_map="auto",
            trust_remote_code=True,
            load_in_8bit=True  # Teknova memory optimization
        )
        
        print("âœ… Teknova Nova AI modeli baÅŸarÄ±yla yÃ¼klendi!")
        print("ğŸ‰ Ã–zgÃ¼n Nova AI teknolojisi aktif!")
        return "ğŸš€ Teknova Nova AI hazÄ±r! Ã–zgÃ¼n AI teknolojisiyle sohbet edebilirsiniz."
        
    except Exception as e:
        print(f"âŒ Nova AI model yÃ¼kleme hatasÄ±: {e}")
        return f"âŒ Hata: {str(e)}\nğŸ’¡ Nova AI model dosyalarÄ±nÄ±zÄ± doÄŸru konuma yÃ¼klediÄŸinizden emin olun."

def chat_response(message, history):
    """Teknova Nova AI ile sohbet yanÄ±tÄ± Ã¼ret"""
    global model, tokenizer
    
    if model is None or tokenizer is None:
        return "âŒ Teknova Nova AI henÃ¼z yÃ¼klenmedi. LÃ¼tfen model yÃ¼klenmesini bekleyin..."
    
    if not message.strip():
        return "â“ Nova AI'ya mesajÄ±nÄ±zÄ± yazÄ±n."
    
    try:
        # Sohbet geÃ§miÅŸini Nova AI formatÄ±nda hazÄ±rla
        conversation = ""
        for user_msg, bot_msg in history:
            conversation += f"KullanÄ±cÄ±: {user_msg}\nNova AI: {bot_msg}\n"
        
        # Yeni mesajÄ± ekle
        conversation += f"KullanÄ±cÄ±: {message}\nNova AI:"
        
        # Nova AI Tokenizer ile iÅŸle
        inputs = tokenizer(
            conversation, 
            return_tensors="pt", 
            truncation=True, 
            max_length=2048
        ).to(model.device)
        
        # Nova AI yanÄ±t Ã¼ret - Teknova optimizasyonu
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=512,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id,
                eos_token_id=tokenizer.eos_token_id
            )
        
        # Nova AI yanÄ±tÄ±nÄ± decode et
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # Sadece Nova AI'Ä±n yeni yanÄ±tÄ±nÄ± al
        new_response = response[len(conversation):].strip()
        
        return new_response
        
    except Exception as e:
        return f"âŒ Nova AI yanÄ±t Ã¼retirken hata: {str(e)}"

# Model yÃ¼klemeyi baÅŸlat
load_model()

# Gradio arayÃ¼zÃ¼ oluÅŸtur
with gr.Blocks(
    theme=gr.themes.Soft(),
    title="Nova AI Chat - Teknova",
    css="""
    .gradio-container {
        max-width: 800px;
        margin: 0 auto;
    }
    .chat-message {
        border-radius: 10px;
        padding: 10px;
        margin: 5px 0;
    }
    """
) as demo:
    
    gr.HTML("""
    <div style="text-align: center; padding: 20px;">
        <h1 style="background: linear-gradient(135deg, #ff6b6b, #4ecdc4); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-size: 2.5rem; font-weight: bold;">
            ğŸš€ Teknova Nova AI
        </h1>
        <p style="font-size: 1.2rem; color: #666; margin: 10px 0;">
            <strong>Teknova</strong> tarafÄ±ndan geliÅŸtirilen <strong>Ã¶zgÃ¼n</strong> yapay zeka modeli
        </p>
        <div style="background: linear-gradient(135deg, #ff6b6b, #4ecdc4); color: white; padding: 8px 16px; border-radius: 20px; display: inline-block; font-size: 0.9rem;">
            âš¡ Ã–zgÃ¼n Nova AI Teknolojisi â€¢ ğŸ§  Teknova Innovation
        </div>
        <p style="font-size: 0.9rem; color: #888; margin-top: 10px;">
            ğŸŒŸ Bu tamamen Ã¶zgÃ¼n bir Teknova Nova AI modelidir - Token gerektirmez
        </p>
    </div>
    """)
    
    chatbot = gr.Chatbot(
        height=500,
        show_label=False,
        show_share_button=False,
        show_copy_button=True,
        avatar_images=[
            None,  # User avatar
            "ğŸ¤–"   # Bot avatar
        ]
    )
    
    with gr.Row():
        msg = gr.Textbox(
            placeholder="Nova AI'ya mesajÄ±nÄ±zÄ± yazÄ±n...",
            show_label=False,
            scale=4
        )
        submit = gr.Button("ğŸš€ GÃ¶nder", scale=1, variant="primary")
    
    with gr.Row():
        clear = gr.Button("ğŸ—‘ï¸ Temizle", scale=1)
        
    gr.HTML("""
    <div style="text-align: center; padding: 10px; color: #666;">
        <small>ğŸ’¡ Teknova Nova AI ilk yÃ¼klenirken biraz bekleyebilir. Ã–zgÃ¼n AI teknolojisi ile gÃ¼Ã§lendirilmiÅŸtir.</small>
        <br>
        <small style="color: #ff6b6b;">ğŸš€ <strong>Teknova Nova AI</strong> - Tamamen Ã¶zgÃ¼n model teknolojisi</small>
        <br>
        <small style="color: #4ecdc4;">ğŸŒŸ Hugging Face token gerektirmez - Kendi modeliniz!</small>
    </div>
    """)
    
    # Event handlers
    def user_message(message, history):
        return "", history + [[message, None]]
    
    def bot_message(history):
        user_message = history[-1][0]
        bot_response = chat_response(user_message, history[:-1])
        history[-1][1] = bot_response
        return history
    
    msg.submit(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(
        bot_message, chatbot, chatbot
    )
    submit.click(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(
        bot_message, chatbot, chatbot
    )
    clear.click(lambda: None, None, chatbot, queue=False)

if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True
    ) 